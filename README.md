# AlphaCognate

AlphaCognate is a tool for the functional annotation of predicted protein structures via cognate ligand transplantation, enabling large-scale transplantation of ligands with known cognate mappings into predicted structures.

## Installation

To install AlphaCognate, clone the repository and install the required dependencies in a virtual environment (we recommend using [UV](https://docs.astral.sh/uv/getting-started/installation/) for extremly fast installation, but you can also use pip):

```bash
git clone https://github.com/m-crown/AlphaCognate.git
cd AlphaCognate/alphacognate_pipeline
uv venv --python=3.11
source .venv/bin/activate
uv pip install -r requirements.txt
```

In addition to the Python dependencies, AlphaCognate also requires FoldSeek for structure searching. To install FoldSeek, download the latest appropriate binary file from the [FoldSeek GitHub repo](https://github.com/steineggerlab/foldseek) (example below is shown for Linux with AVX2, binaries are available for Linux ARM64, MacOS and GPU enable - note this is not tested in AlphaCognate).

First, activate the virtual environment:

```bash
cd AlphaCognate/alphacognate_pipeline
source .venv/bin/activate
```

Then download the FoldSeek binary. For Linux, the command is:

```bash
curl -L https://mmseqs.com/foldseek/foldseek-linux-avx2.tar.gz -o foldseek-linux-avx2.tar.gz && \
tar xvzf foldseek-linux-avx2.tar.gz && \
export PATH="$(pwd)/foldseek/bin/:$PATH"
```

For MacOS, the command is slightly different (note that the binary is universal and will work on both Intel and M1/M2 Macs):

```bash
curl -L https://mmseqs.com/foldseek/foldseek-osx-universal.tar.gz -o foldseek-osx-universal.tar.gz && \
tar xvzf foldseek-osx-universal.tar.gz && \
export PATH="$(pwd)/foldseek/bin:$PATH"
```

Finally, check that FoldSeek is installed correctly

```bash
foldseek version
```

## Pre-requisites

AlphaCognate requires a directory of predicted structure files and an accompanying manifest file. If you need to download the predicted structure files from the AlphaFold database this can be done using the following helper command and an input file containing the list of UniProt IDs (one per line, replace $UNIPROTIDS_FILE with your file and $OUTPUTDIRECTORY with the directory you want to save the structures in):

```bash
python3 bin/get_alphafold_structures.py $UNIPROTIDS_FILE --output_dir $OUTPUTDIRECTORY
```

The accompanying comma separated manifest file should contain the following columns (without a header row):

- structure basename: The basename of the structure, e.g. AF-A0A023GPK8-F1-model_4
- filename: The filename of the structure, e.g. AF-A0A023GPK8-F1-model_4.cif
- directory: The directory containing the structure, e.g. alphafold_structures/

This manifest file can be generated by using the following helper command and specify the directory in which the structure files are located (replace $STRUCTURE_DIRECTORY with the directory containing the structure files):

```bash
python3 bin/make_manifest.py $STRUCTURE_DIRECTORY
```

The manifest file can then be provided in the Snakemake command (see [Running AlphaCognate](#running-the-alphacognate-pipeline)) either as part of a config file (recommended) or directly as a command line argument e.g.:

```snakemake --configfile config.yaml```
or

```snakemake --config manifest=manifest.csv```

Finally, AlphaCognate requires a domain assignments file which contains the domain boundaries predicted by CATH for the input predicted structures. This file should be a TSV file with the following columns (including a header row):

- accession: The basename of the structure, e.g. AF-A0A023GPK8-F1-model_4 - this should match the structure basename in the manifest file.
- domain_profile: The ID and residue range of the domains predicted in the structure (separated with a colon), with multiple domains semicolon delimited. For example for a structure with a single domain prediction: `2.60.40.10:122-228` and for a structure with multiple domains: `1.10.1380.10:150-448;3.40.390.10:453-765`. Where domains are segmented, multiple ranges are separated with an underscore e.g. `1.10.1380.10:150-448_502-765`.

The domain assignments files are pre-generated using the CATH domain assignments from either [AlphaFold2 reveals commonalities and novelties in protein structure space for 21 model organisms](https://www.nature.com/articles/s42003-023-04488-9) or [Exploring structural diversity across the protein universe with The Encyclopedia of Domains](https://www.science.org/doi/10.1126/science.adq4946) using the following helper command:

```bash
cd alphacognate_pipeline
source .venv/bin/activate
python3 bin/format_cath_af_domains.py
python3 bin/format_cath_af_domains.py --ted
```

These files are uploaded to Zenodo and are downloaded within the pipeline depending on the config parameter set - set `domains` to `ted` in `config.yaml` to use the TED domains, and do not set `domains` or set to `cath-alphafold` to use the CATH-AlphaFold formatted domains.

## Running The AlphaCognate Pipeline

To run AlphaCognate, the pipeline is executed with Snakemake. The workflow is designed to be run from the command line and requires the manifest file and domain assignments (see [Pre-requisites](#pre-requisites)) as input.

For the TL;DR version, the following command will run the pipeline with default parameters:

```bash  
snakemake -s alphacognate_pipeline.smk --configfile alphacognate_config.yaml --cores 1
```

A demo analysis can be performed to examine the outputs of AlphaCognate using the following command:

```bash  
snakemake -s alphacognate_pipeline.smk --config demo=demo
```

Which runs five predicted structures from AlphaFold against a small subset of experimental assemblies with cognate ligand mappings in ProCogGraph.

AlphaCognate runtime benefits significantly from increased thread count, which helps speed-up both FoldSeek and allow for parallel transplantations. STATEMENT HERE ON RUNTIME WITH X AND Y THREADS.

Note: Files from the ProCogGraph database (see [here](https://doi.org/10.1093/bioadv/vbae161)) are required for running AlphaCognate. These are downloaded in a preprocessing step of the pipeline, download size:

- 137MB zipped
- 693MB unzipped

Additionally, the pipeline requires the download of the protonated assemblies of structures present in the ProCogGraph mapping. For the demo output, a subset of 45 structures are downloaded (total download size approx. 15MB), but to run the full pipeline against all structures present in the ProCogGraph mapping, approx. 60,000 structures are required. The download size of these files is approx. 15GB.

### Configuration

The pipeline is configured using a YAML file, which can be specified using the `--configfile` option. The configuration file should contain the following parameters:

- `structure_manifest`: The path to the manifest file containing the structure basenames, filenames, and directories.
- `output_dir`: The directory to store analysis output in.
- `cognate_match`: true/false, when set to true only ligands with a cognate mapping in ProCogGraph will be transplanted.
- `domain_match`: true/false, when set to true only transplants with a matching domain interaction profile to the experimentally observed ligand interaction will be retained.
- `domains`: either "cath-alphafold" or "ted". This flag alters the pre-formatted predicted structure domain profiles which are used for analysis of domain-ligand interactions. See [pre-requisites](#pre-requisites).
- `top_ranked`: True/False, when set to True only the top ranked ligand transplant per binding site per structure is retained.

### Running the Webapp

Following completion of an analysis, data can be loaded and visualsied in the webapp. The webapp consists of a Docker compose file used to create a backend FastAPI server, frontend Nginx server (serving a React app) and a PostgreSQL database.

To load data into the webapp, do the following:

1. Copy the combined_transplant.tsv.gz and combined_structures.tsv.gz files along with the transplanted cif files to the cif-files directory in the webapp directory.
2. Load the information into the database using the following command:

    ```bash
    docker compose up -d postgres
    python3 database.py
    docker compose down postgres
    ```

3. Start the webapp using the following command:

```bash
docker compose up
```

The webapp will be available at http://localhost:80.

For development, run only the postgresdb and nginx containers:

```bash
docker compose up -d postgres
docker compose up -d nginx
```

Then run the FastAPI server in a separate terminal:

```bash
fastapi run alphacognate_webapp/app.py
```

And run the React app in a separate terminal:

```bash
cd alphacognate_webapp/frontend
npm run dev
```

MAKE A NOTE SOMEWHERE IN THE README THAT NRGRANK PROCESS CAN OPERATE ONLY ON LIGANDS WITHOUT R GROUPS AND DUMMY ATOMS - SO SOME COGNATE LIGANDS WILL BE EXCLUDED FROM THE RANKING PROCESS.
